{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c074225a-d3f5-48eb-bece-7bb867357256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from koinapy import Koina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bd5b2dc-c0b6-4e93-8ea8-81b62e410b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\AppData\\Local\\Temp\\ipykernel_25500\\892803512.py:2: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(fp, delimiter='\\t')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(799991, 57)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = r\"C:\\Users\\student\\Desktop\\Claire_multiprotease_ULB-Virions-Local\\ULB_eFASP_multiprotease\\2025-11-10-12-50-38\\Task2-SearchTask\\AllPeptides.psmtsv\"\n",
    "df = pd.read_csv(fp, delimiter='\\t')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70749469-e9f4-421d-95fb-d3f8d5807749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(770633, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pc = 6 # Maximum allowed precursor charge\n",
    "max_len = 30 # Maximum allowed sequence length\n",
    "min_len = 7 # Minimum allowed sequence length\n",
    "\n",
    "filtered = df.loc[:, [\"Base Sequence\", \"Precursor Charge\"]]\n",
    "len_filter = filtered[\"Base Sequence\"].map(lambda x: min_len<=len(x)<=max_len)\n",
    "pc_filter = filtered[\"Precursor Charge\"].map(lambda x: x<=max_pc)\n",
    "\n",
    "filtered = filtered[(len_filter) & (pc_filter)]\n",
    "filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a94c3c04-e752-4ec8-a10b-641bd8b8c2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Koina(\"Prosit_2020_intensity_CID\", \"koina.wilhelmlab.org:443\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d55554df-7694-46f6-85a4-93e3b22773f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = filtered.rename(columns={\"Base Sequence\":\"peptide_sequences\", \"Precursor Charge\": \"precursor_charges\"},\n",
    "                          inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3aabfd3e-b483-4396-b945-8ad9c49261e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ee9b45e8824f3d97e315c76bdbb92b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prosit_2020_intensity_CID::   0%|          | 0/771 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\miniconda3\\envs\\pyms\\Lib\\site-packages\\koinapy\\grpc.py:762: UserWarning: in ensemble 'Prosit_2020_intensity_CID', Failed to process the request(s) for model instance 'Prosit_Preprocess_peptide', message: TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "At:\n",
      "  /models/repo/Prosit_Preprocess_peptide/1/sequence_conversion.py(71): character_to_array\n",
      "  /models/repo/Prosit_Preprocess_peptide/1/model.py(25): <listcomp>\n",
      "  /models/repo/Prosit_Preprocess_peptide/1/model.py(25): execute\n",
      "\n",
      "  warnings.warn(res.message(), stacklevel=1)\n"
     ]
    },
    {
     "ename": "InferenceServerException",
     "evalue": "\n                    At least one request failed. Check the error message above and try again.\n                    To get a list of responses run koina.predict(..., debug = True), then call koina.response_dict\n                    ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInferenceServerException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m max_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000000\u001b[39m\n\u001b[1;32m----> 3\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(inputs\u001b[38;5;241m.\u001b[39miloc[:max_inputs])\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pyms\\Lib\\site-packages\\koinapy\\grpc.py:534\u001b[0m, in \u001b[0;36mKoina.predict\u001b[1;34m(self, inputs, mode, debug, df_output, min_intensity, disable_progress_bar)\u001b[0m\n\u001b[0;32m    531\u001b[0m     dict_inputs \u001b[38;5;241m=\u001b[39m inputs\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msemi_async\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 534\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__predict_semi_async(\n\u001b[0;32m    535\u001b[0m         dict_inputs, debug\u001b[38;5;241m=\u001b[39mdebug, disable_progress_bar\u001b[38;5;241m=\u001b[39mdisable_progress_bar\n\u001b[0;32m    536\u001b[0m     )\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masync\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__predict_async(\n\u001b[0;32m    539\u001b[0m         dict_inputs, debug\u001b[38;5;241m=\u001b[39mdebug, disable_progress_bar\u001b[38;5;241m=\u001b[39mdisable_progress_bar\n\u001b[0;32m    540\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pyms\\Lib\\site-packages\\koinapy\\grpc.py:650\u001b[0m, in \u001b[0;36mKoina.__predict_semi_async\u001b[1;34m(self, data, debug, disable_progress_bar)\u001b[0m\n\u001b[0;32m    643\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(\n\u001b[0;32m    644\u001b[0m     total\u001b[38;5;241m=\u001b[39mceil(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(data\u001b[38;5;241m.\u001b[39mvalues()))\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatchsize),\n\u001b[0;32m    645\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    646\u001b[0m     disable\u001b[38;5;241m=\u001b[39mdisable_progress_bar,\n\u001b[0;32m    647\u001b[0m )\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data_batch \u001b[38;5;129;01min\u001b[39;00m data_subsets:\n\u001b[0;32m    649\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 650\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__predict_async(data_batch, debug\u001b[38;5;241m=\u001b[39mdebug, pbar_input\u001b[38;5;241m=\u001b[39mpbar)\n\u001b[0;32m    651\u001b[0m     )\n\u001b[0;32m    652\u001b[0m pbar\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__merge_list_dict_array(results)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pyms\\Lib\\site-packages\\koinapy\\grpc.py:731\u001b[0m, in \u001b[0;36mKoina.__predict_async\u001b[1;34m(self, data, debug, disable_progress_bar, pbar_input)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pbar_input \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    729\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 731\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__handle_results(infer_results, debug)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pyms\\Lib\\site-packages\\koinapy\\grpc.py:764\u001b[0m, in \u001b[0;36mKoina.__handle_results\u001b[1;34m(self, infer_results, debug)\u001b[0m\n\u001b[0;32m    762\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(res\u001b[38;5;241m.\u001b[39mmessage(), stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 764\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InferenceServerException(\n\u001b[0;32m    765\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    766\u001b[0m \u001b[38;5;124;03m        At least one request failed. Check the error message above and try again.\u001b[39;00m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;124;03m        To get a list of responses run koina.predict(..., debug = True), then call koina.response_dict\u001b[39;00m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n\u001b[0;32m    769\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mInferenceServerException\u001b[0m: \n                    At least one request failed. Check the error message above and try again.\n                    To get a list of responses run koina.predict(..., debug = True), then call koina.response_dict\n                    "
     ]
    }
   ],
   "source": [
    "max_inputs = 1000000\n",
    "\n",
    "prediction = model.predict(inputs.iloc[:max_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64ae8624-2233-4e08-82c8-142a23567175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4331974, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyms_kernel",
   "language": "python",
   "name": "pyms_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
